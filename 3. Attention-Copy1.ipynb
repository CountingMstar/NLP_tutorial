{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dictionary = {w: i for i, w in enumerate(word_list)}\n",
    "number_dictionary = {i: w for i, w in enumerate(word_list)}\n",
    "dictionary_size = len(word_dictionary)  # vocab list\n",
    "dictionary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = np.eye(dictionary_size)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]]),\n",
       " tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]]),\n",
       " tensor([[ 7,  5,  0,  4, 10]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_batch(sentences):\n",
    "    input_ = [word_dictionary[word] for word in sentences[0].split()]\n",
    "    output_ = [word_dictionary[word] for word in sentences[1].split()]\n",
    "    target_ = [word_dictionary[word] for word in sentences[2].split()]\n",
    "    \n",
    "    onehot_input = [one_hot[i] for i in input_]\n",
    "    onehot_output = [one_hot[i] for i in output_]\n",
    "\n",
    "    input_tensor = torch.FloatTensor([onehot_input])\n",
    "    output_tensor = torch.FloatTensor([onehot_output])\n",
    "    target_tensor = torch.LongTensor([target_])\n",
    "    \n",
    "    return input_tensor, output_tensor, target_tensor\n",
    "\n",
    "\n",
    "sentence_to_batch(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_cell = nn.RNN(input_size=dictionary_size, hidden_size=hidden_size, dropout=0.2)\n",
    "        self.decoder_cell = nn.RNN(input_size=dictionary_size, hidden_size=hidden_size, dropout=0.2)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size * 2, dictionary_size)\n",
    "\n",
    "\n",
    "    def forward(self, encoder_inputs, hidden, decoder_inputs):\n",
    "        encoder_inputs = encoder_inputs.transpose(0, 1) \n",
    "        decoder_inputs = decoder_inputs.transpose(0, 1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder_cell(encoder_inputs, hidden)\n",
    "\n",
    "        trained_attention = []\n",
    "        hidden = encoder_hidden\n",
    "        number_of_cells = len(decoder_inputs)\n",
    "        model = torch.empty([number_of_cells, 1, dictionary_size])\n",
    "\n",
    "        for i in range(number_of_cells):  \n",
    "            \n",
    "            decoder_output, hidden = self.decoder_cell(decoder_inputs[i].unsqueeze(0), hidden)\n",
    "            attention_weights = self.attention_weight(decoder_output, encoder_outputs) \n",
    "            trained_attention.append(attention_weights.squeeze().data.numpy())\n",
    "        \n",
    "            context = attention_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "            decoder_output = decoder_output.squeeze(0) \n",
    "            context = context.squeeze(1) \n",
    "     \n",
    "            model[i] = self.out(torch.cat((decoder_output, context), dim=1))\n",
    "\n",
    "        model = model.transpose(0, 1).squeeze(0)\n",
    "        \n",
    "        return model, trained_attention\n",
    "\n",
    "    def attention_weight(self, decoder_output, encoder_outputs): \n",
    "        number_of_cells = len(encoder_outputs)\n",
    "        attn_scores = torch.zeros(number_of_cells)\n",
    "\n",
    "        for i in range(number_of_cells):\n",
    "            attn_scores[i] = self.attention_score(decoder_output, encoder_outputs[i])\n",
    "        \n",
    "        attention_value = F.softmax(attn_scores).view(1, 1, -1)\n",
    "        return attention_value\n",
    "\n",
    "    def attention_score(self, decoder_output, encoder_output):\n",
    "        decoder_hidden_state = decoder_output\n",
    "        encoder_hidden_state = encoder_output\n",
    "        score = torch.dot(decoder_hidden_state.view(-1), encoder_hidden_state.view(-1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (encoder_cell): RNN(11, 128, dropout=0.2)\n",
       "  (decoder_cell): RNN(11, 128, dropout=0.2)\n",
       "  (out): Linear(in_features=256, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128 # number of hidden units in one cell\n",
    "\n",
    "hidden = torch.zeros(1, 1, hidden_size)\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = sentence_to_batch(sentences)\n",
    "\n",
    "Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000489\n",
      "Epoch: 0800 cost = 0.000159\n",
      "Epoch: 1200 cost = 0.000079\n",
      "Epoch: 1600 cost = 0.000047\n",
      "Epoch: 2000 cost = 0.000031\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_batch = [np.eye(dictionary_size)[[word_dictionary[n] for n in 'SPPPP']]]\n",
    "test_batch = torch.FloatTensor(test_batch)\n",
    "predict, trained_attention = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dictionary[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \"\"\"\n",
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAE2CAYAAADyN1APAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARdUlEQVR4nO3debCddX3H8feHJIQBxCmIA7KlguuoOBhQcSEdacE6znSU0dFqFWYMaq2ouExrUTvqULcRK4pGHaMz2KrV0Yo7lQw6ZYvWKkUFFYWwGRZZErJAvv3jPLGH4y/LvbnnPif3vl8zZ5L7PM85z/e5J/ed5zznJjdVhSTpgfboewBJmkTGUZIajKMkNRhHSWowjpLUYBwlqcE4DkmyMskFO7HdkiSVZOlszNWH7vhO6XuOXbU7HUeSVUnOne56zayFfQ8wYc4A0vcQu4MkS4BrgWOranXP42zPwcAdfQ8xQ54HbO57iHFIshJ4WffhfcD1wJeBt1fVuj5mMo5DqurOvmfQzKqqm/ueYaZU1e27+hhJFlXVpAb2QuClwCLgGcAngX2AV/UxjC+rhwy/rM7AmUmuSbIxyZokZ4/c5Ygk302yPslVSf58THOtSnJekg8kuT3J2iRnJFmc5CNJfp/kuiQvHbrP45NcmOTe7j4rkzx45HFfluSn3fHdkuQzI7veP8kXk6xL8uskLxlad2336xXdS9dVQ497avf52JDk6iSvTzKWP2vd8/TmJL/qjvWnw3MOv6weuhzy/Nl43qZpYZIPJbmju71v6+du9GV1kj2TvKf7s7k+yRVJThpav6w73r9McnmSTcBJjX1Oio1VdXNVXV9VnwPOB/6qt2mqylt3A1YCF3S/Pxv4PXAacBTwVODV3bolQAE/B54LPAL4DHAbsO8Y5loF3AW8o9vXmd3+v8ngUsBRwDuBjQxeRu4D3Ah8BXg8cAJwNfClocc8HdgAvAF4FPAk4E1D6wtYA7yke/yzgU3A4d36Y7ttTgIOAvbvlr8CuAk4BfjT7vNzM/CaMT1n7wZ+AZzc7e/FwDrgOUPHcUofz9s0n+e7gQ8DjwZeANwJvGFo/blD258PXAo8E3g48JruOTq6W7+sO96fAn/RbXNg38e5o6+9oWX/Atza20x9f1Im6bb1CQL27cLxym1st/WL7PShZYd0y54+hrlWAZcMfRxgLfAfQ8sWdV8Yp3SBuhN40ND6rV8oR3UfrwH+eTv7LODsoY8XAuuBl4x8DpaO3O864KUjy14HXDWGz8s+wL3AM0aWnwN8Y+g4RuM4K8/bNJ/nq4EMLftHYM3Q+nO73x8JbKH7y2po+68AHx15zp/f97HtxLE/II7AccCtwOf7mslrjm2PBRYD/7mD7X4y9Psbu18fOpaJhvZVVZXkdwzOCLYu25zkjm7/RwE/qaq7h+7/Xwy+mB6b5C4GUdjp46uq+5KsZTvHl+RA4DDg40nOG1q1kPG80fVYYC/gW0mG/weVRcBvtnO/2XzepurS6urQuQR4Z5L9RrY7hsHn9KrkAZ/axcD3Rrad5DfMhp2c5B4Gf14WAV8F/q6vYYzjrvnDhe0uWDC+67ijF9FrG8t2tP+p/DdMU338reteySDG47Z1f89lcMY6bHtvOszm8zYuezB4Po7lj4/13pGPe3m3dxouBpYzOJ4bq+c3joxj288YXL97FnBNz7NMx8+A05I8aOjs8XgGX1A/q6rfJbmBwfF9d5r72NT9umDrgqq6JcmNwJFV9dlpPu5UXMXgeTqiqkbPlnZXT06SobPHpzAIxV0jZ4j/zeDM8aCqumi2hxyT9VX1y76H2Mo4NlTV3Uk+BJydZCODv9EOAJ5UVedt/94T4Xzgn4DPJnkb8CfAx4EvD/3hezfwwSS3AF8H9gaeVVUf2Ml9/I7BGcpJSX4DbKjBt0K9Hfhwkt8D32Dw8ugY4JCqGn23f5d0z9P7gfdnUI6LGVwvfgqwpapWzOT+ZsnDgHOSfJTBm2lvAt41ulFVXZ3kfGBlkjOBHwH7M7jO+Ouq+vLsjTw3Gcdt+3sG3zx8FnAocAswG2dDu6yq1nff0nEOcDmDN5e+yuCd7a3bnNd9a8eZwHuA2xnEbGf3cV+S1wJvYxDE7wPLquqTSdYx+KI+m0FA/xcY17/sOIvBc/NG4DwG7+r/GHjvmPY3buczOBu/jMHL5k8BH9zGtqcCb2VwrIcyeA4vB+bKmWSv8sBrv5Ik2P0uQkvSrDCOktRgHCWpwThKUoNxlKQG4yhJDcZxipIs73uGcZirxwVz99g8rvEyjlM3EU/cGMzV44K5e2we1xgZR0lqmBP/QuYh+y+oJYctmpV9rb3tfg48YMGON5wB11y576zsB2BTbWDP7DVr+6stW2ZtX5vZyCIWz9r+ZovHNTPu5o5bq+rA0eVz4t9WLzlsEZd/+7C+x5hxzz7q+L5HGJst947+r1pzxBw42ZhvLqx//21ruS+rJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNEx3HJCuTXND3HJLmn0n/6YNnAOl7CEnzz0THsaru7HsGSfOTL6slqWGi4yhJfdlt45hkeZLVSVavve3+vseRNMfstnGsqhVVtbSqlh54wIK+x5E0x+y2cZSkcTKOktRgHCWpwThKUsOkfxP4y/ueQdL85JmjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1DDRP0NmZ22hWL9lU99jzLyk7wnGp6rvCcZjDj9nWbCg7xHGY3N7sWeOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1TGQck6xKcm7fc0iavyYyjpLUtx3GMcnJSe5OsrD7+KgkleRjQ9u8K8mFSRYk+VSSa5Pcm+SaJG9OssfQtiuTXJDkjCQ3JLkjyaeT7L11PXAC8LfdfirJkpk+cEnanoU7sc0PgL2ApcClwDLg1u7XrZYB32IQ2xuAFwBrgeOAFcBtwKeGtn8GcBNwInAY8AXgauBs4AzgkcDPgX/otl87tcOSpF2zwzPHqroH+CHwZ92iZcC5wBFJDu7O+I4FVlXV5qp6W1VdUVW/qaovAB8DXjTysHcBr6yqn1XVd4AvAs/q9ncnsAlYX1U3d7f7R+dKsjzJ6iSrb73tj1ZL0i7Z2WuOq/j/M8UTgG8Cl3XLjgfuAy4HSPLKLlprk9wDvB44fOTxrhoJ3o3AQ6cyeFWtqKqlVbX0IQcsmMpdJWmHphLHpyV5DLAfgzPJVQzOJpcBl1TVpiQvBM4BVgInAU8EPgrsOfJ4m0c+rinMIkljtzPXHGFw3XEx8GbgB1V1f5JVwCeAWxhcbwR4OnBZVf3h23CSHDmNuTYBng5K6s1Ona0NXXd8CXBRt/hS4FDgKQzOImHwpsoxSZ6d5BFJzmLwMnyqfgMcl2RJkocMv9stSbNhKtFZxeBMcxVAVW1gcN1xI931RuDjDN55/hxwBbAE+MA05no/g7PHqxi8Uz16zVKSxipV1fcMu+yYoxfXxd88qO8xZtzzH/VnO95oN7Vl3bq+RxiPpO8JxiYL5uaVru9u/rcfVtXS0eW+XJWkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNezsz62eaL/86T48b8nxfY8x437xiUf3PcLY7H3N4r5HGIvDz/lx3yOMzZYNG/seYVZ55ihJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDRMVxyQnJ/l+kjuS3J7k20ke0/dckuafiYojsA9wDnAcsAy4E/hakj1HN0yyPMnqJKs318ZZHVLS3Lew7wGGVdWXhj9OcipwF4NY/mBk2xXACoD99ti/ZmtGSfPDRJ05JjkyyeeS/CrJXcAtDGY8vOfRJM0zE3XmCFwArAFOB24A7gOuAv7oZbUkjdPExDHJAcCjgVdX1UXdsmOYoBklzR+TFJ47gFuBVyS5HjgEeB+Ds0dJmlUTc82xqrYALwSeAFwJfAQ4C/CtaEmzbpLOHKmq7wGPG1m8bx+zSJrfJubMUZImiXGUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNE/UzZKatoO6bez+k8JGn/ajvEcZmwYP363uEsbj2zU/se4Sx2XDw5r5HGI/ln28u9sxRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUsOU4phkVZJzxzWMJE0KzxwlqWHi45hkz75nkDT/TCeOC5N8KMkd3e19SfaAQciSvCfJmiTrk1yR5KThOyd5bJKvJ7k7ye+S/GuSg4bWr0xyQZK3JFkDrNm1Q5SkqZtOHP+6u99TgdOB5cDrunWfBk4AXgw8DvgM8LUkRwMkORi4GLgSOA44EdgX+OrWwHZOAJ4AnAw8axozStIuWTiN+9wEvLaqCvh5kkcCb0jyVeBFwJKquq7b9twkJzKI6KuBVwH/U1Vv2fpgSf4GuB1YClzeLd4AnFZVG7c1RJLlDMLMXuw9jcOQpG2bzpnjpV0Yt7oEOAR4OhDgqiT3bL0BzwGO7LZ9EvDMkfXXd+uOHHrMK7cXRoCqWlFVS6tq6SIWT+MwJGnbpnPmuD0FHAtsHll+b/frHsDXgTc27nvL0O/XzfBckjQl04njk5Nk6OzxKcCNDM4gAxxUVRdt474/Al4A/LaqRgMqSRNjOi+rHwack+RRSU4B3gR8sKquBs4HViY5JcnDkyxN8sYkz+vu+xHgwcDnkzy52+bEJCuSPGhGjkiSZsB0zhzPBxYAlzF4Gf0p4IPdulOBtwLvBQ5l8EbL5cBFAFV1Y5KnAWcD3wL2Aq4DvgNs9xqjJM2mKcWxqpYNffiaxvrNwDu627Ye4xrglO2sf/lUZpKkcZj4fyEjSX0wjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqWGmf261ZtIffvrt3LNl3b073mg3tOjuvicYn4VHz68fJ++ZoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDRMTxyQrk1Tjdmnfs0mafxb2PcCIC4GXjizb1Mcgkua3SYvjxqq6ue8hJGliXlZL0iSZtDienOSekdt7WhsmWZ5kdZLVm9k423NKmuMm7WX1xcDykWW/b21YVSuAFQD7Zf8a71iS5ptJi+P6qvpl30NI0qS9rJakiTBpZ46Lkxw0suz+qlrbyzSS5q1Ji+OJwE0jy24ADu1hFknz2MS8rK6ql1dVGjfDKGnWTUwcJWmSGEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpIVXV9wy7LMla4LeztLuHALfO0r5m01w9Lpi7x+ZxzYwjqurA0YVzIo6zKcnqqlra9xwzba4eF8zdY/O4xsuX1ZLUYBwlqcE4Tt2KvgcYk7l6XDB3j83jGiOvOUpSg2eOktRgHCWpwThKUoNxlKQG4yhJDf8Hwyug3tKZeDAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attention, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
