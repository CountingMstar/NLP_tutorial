{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dictionary = {w: i for i, w in enumerate(word_list)}\n",
    "number_dictionary = {i: w for i, w in enumerate(word_list)}\n",
    "dictionary_size = len(word_dictionary)  # vocab list\n",
    "dictionary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = np.eye(dictionary_size)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]]),\n",
       " tensor([[2, 0, 9, 6, 3]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_to_batch(sentences):\n",
    "    input_ = [word_dictionary[word] for word in sentences[0].split()]\n",
    "    output_ = [word_dictionary[word] for word in sentences[1].split()]\n",
    "    target_ = [word_dictionary[word] for word in sentences[2].split()]\n",
    "    \n",
    "    onehot_input = [one_hot[i] for i in input_]\n",
    "    onehot_output = [one_hot[i] for i in output_]\n",
    "\n",
    "    input_tensor = torch.FloatTensor([onehot_input])\n",
    "    output_tensor = torch.FloatTensor([onehot_output])\n",
    "    target_tensor = torch.LongTensor([target_])\n",
    "    \n",
    "    return input_tensor, output_tensor, target_tensor\n",
    "\n",
    "\n",
    "sentence_to_batch(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_cell = nn.RNN(input_size=dictionary_size, hidden_size=hidden_size, dropout=0.2)\n",
    "        self.decoder_cell = nn.RNN(input_size=dictionary_size, hidden_size=hidden_size, dropout=0.2)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size * 2, dictionary_size)\n",
    "\n",
    "\n",
    "    def forward(self, encoder_inputs, hidden, decoder_inputs):\n",
    "        encoder_inputs = encoder_inputs.transpose(0, 1) \n",
    "        decoder_inputs = decoder_inputs.transpose(0, 1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder_cell(encoder_inputs, hidden)\n",
    "\n",
    "        trained_attention = []\n",
    "        hidden = encoder_hidden\n",
    "        number_of_cells = len(decoder_inputs)\n",
    "        model = torch.empty([number_of_cells, 1, dictionary_size])\n",
    "\n",
    "        for i in range(number_of_cells):  \n",
    "            \n",
    "            decoder_output, hidden = self.decoder_cell(decoder_inputs[i].unsqueeze(0), hidden)\n",
    "            attention_weights = self.attention_weight(decoder_output, encoder_outputs) \n",
    "            trained_attention.append(attention_weights.squeeze().data.numpy())\n",
    "        \n",
    "            context = attention_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "            decoder_output = decoder_output.squeeze(0) \n",
    "            context = context.squeeze(1) \n",
    "     \n",
    "            model[i] = self.out(torch.cat((decoder_output, context), dim=1))\n",
    "\n",
    "        model = model.transpose(0, 1).squeeze(0)\n",
    "        \n",
    "        return model, trained_attention\n",
    "\n",
    "    def attention_weight(self, decoder_output, encoder_outputs): \n",
    "        number_of_cells = len(encoder_outputs)\n",
    "        attn_scores = torch.zeros(number_of_cells)\n",
    "\n",
    "        for i in range(number_of_cells):\n",
    "            attn_scores[i] = self.attention_score(decoder_output, encoder_outputs[i])\n",
    "        \n",
    "        attention_value = F.softmax(attn_scores).view(1, 1, -1)\n",
    "        return attention_value\n",
    "\n",
    "    def attention_score(self, decoder_output, encoder_output):\n",
    "        decoder_hidden_state = decoder_output\n",
    "        encoder_hidden_state = encoder_output\n",
    "        score = torch.dot(decoder_hidden_state.view(-1), encoder_hidden_state.view(-1))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attention(\n",
       "  (encoder_cell): RNN(11, 128, dropout=0.2)\n",
       "  (decoder_cell): RNN(11, 128, dropout=0.2)\n",
       "  (out): Linear(in_features=256, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128 # number of hidden units in one cell\n",
    "\n",
    "hidden = torch.zeros(1, 1, hidden_size)\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "input_batch, output_batch, target_batch = sentence_to_batch(sentences)\n",
    "\n",
    "Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000492\n",
      "Epoch: 0800 cost = 0.000162\n",
      "Epoch: 1200 cost = 0.000081\n",
      "Epoch: 1600 cost = 0.000048\n",
      "Epoch: 2000 cost = 0.000032\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_batch = [np.eye(dictionary_size)[[word_dictionary[n] for n in 'SPPPP']]]\n",
    "test_batch = torch.FloatTensor(test_batch)\n",
    "predict, trained_attention = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dictionary[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \"\"\"\n",
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attention, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
