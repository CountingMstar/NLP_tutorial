{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = torch.empty([n_step, 1, n_class])\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000475\n",
      "Epoch: 0800 cost = 0.000154\n",
      "Epoch: 1200 cost = 0.000076\n",
      "Epoch: 1600 cost = 0.000045\n",
      "Epoch: 2000 cost = 0.000029\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/home/moonstar/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAE2CAYAAADyN1APAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARPklEQVR4nO3deayldX3H8fcHZhgCiBXFICCg4EZcCA6LijINtENrTBolGi1UMWFAa0XFJa1FbdRQXAJWFB0ljibYuEYqoiiVCZKyjRaXDhZcWIdlkGGHYYBv/zjP2MPxN8PcO3Puc7j3/UpO7tznPOc83+eeuW+e5zl3uKkqJEmPtlXfA0jSJDKOktRgHCWpwThKUoNxlKQG4yhJDcZxSJJlSc7ZhPX2SlJJFs7EXH3o9u/IvufYXI+n/UiyPMnp071fW9a8vgeYMCcA6XuIx4MkewG/Bw6oqhU9j7MxTwPW9D3EFvJqYF3fQ4xDkmXAG7tPHwKuB74NfLCq7u1jJuM4pKru7HsGbVlVdXPfM2wpVXX75j5HkvlVNamBPR84GpgPvBz4IrA98JY+hvG0esjwaXUGTkxydZK1SW5IcvLIQ/ZM8qMk9yVZmeQvxjTX8iRnJPlkktuTrE5yQpIFST6T5I4k1yU5eugxL0hyfpL7u8csS/LEked9Y5Jfdvt3S5Ivj2x6pyTfSHJvkt8lOWrovt93Hy/vTl2XDz3vMd3X44EkVyV5Z5Kx/F3rXqf3Jvltt6+/HJ5z+LR66HLIa2bidZumeUk+lWRNd/v4+q/d6Gl1km2SnNL93bwvyeVJFg/dv6jb379OclmSB4HFjW1OirVVdXNVXV9VXwXOAv6mt2mqylt3A5YB53R/Phm4A3gzsA/wEuCt3X17AQX8GngV8Czgy8AfgB3GMNdy4C7gQ922Tuy2/30GlwL2AT4MrGVwGrk9sAr4DvAC4FDgKuBbQ895HPAA8C7gOcCLgfcM3V/ADcBR3fOfDDwI7NHdf0C3zmJgF2CnbvmxwE3AkcAzuq/PzcDbxvSafRT4X+CIbntvAO4FXjm0H0f28bpN83W+G/g08FzgtcCdwLuG7j99aP2zgEuAVwDPBN7WvUYv6u5f1O3vL4G/7NbZue/9fKzvvaFl/wbc1ttMfX9RJum2/gUCdujCcfwG1lv/TXbc0LLdumWHjGGu5cDFQ58HWA38x9Cy+d03xpFdoO4EnjB0//pvlH26z28A/nUj2yzg5KHP5wH3AUeNfA0WjjzuOuDokWXvAFaO4euyPXA/8PKR5acB5w7tx2gcZ+R1m+brfBWQoWX/DNwwdP/p3Z/3Bh6h+4/V0PrfAT478pq/pu9924R9f1QcgQOB24Cv9TWT1xzb9gUWAP/5GOv9YujPq7qPTx3LREPbqqpKciuDI4L1y9YlWdNtfx/gF1V199Dj/4vBN9O+Se5iEIVN3r+qeijJajayf0l2Bp4OfD7JGUN3zWM8b3TtC2wL/CDJ8P9BZT5wzUYeN5Ov21RdUl0dOhcDH06y48h6+zP4mq5MHvWlXQD8eGTdSX7DbNgRSe5h8PdlPnA28A99DWMcN88fL2x3wYLxXccdvYheG1j2WNufyv+GaarPv/6+4xnEeNzWb+9VDI5Yh23sTYeZfN3GZSsGr8cB/Om+3j/yeS/v9k7DhcASBvuzqnp+48g4tl3J4PrdYcDVPc8yHVcCb07yhKGjx5cy+Ia6sqpuTXIjg/370TS38WD3cev1C6rqliSrgL2r6ivTfN6pWMngddqzqkaPlh6vDkqSoaPHgxmE4q6RI8T/ZnDkuEtVXTDTQ47JfVX1m76HWM84NlTV3Uk+BZycZC2D/6I9GXhxVZ2x8UdPhLOAfwG+kuQDwJOAzwPfHvrL91Hg1CS3AN8DtgMOq6pPbuI2bmVwhLI4yTXAAzX4UagPAp9OcgdwLoPTo/2B3apq9N3+zdK9Tp8APpFBOS5kcL34YOCRqlq6Jbc3Q3YFTkvyWQZvpr0H+MjoSlV1VZKzgGVJTgR+BuzE4Drj76rq2zM38uxkHDfsHxn88PBJwO7ALcBMHA1ttqq6r/uRjtOAyxi8uXQ2g3e2169zRvejHScCpwC3M4jZpm7joSRvBz7AIIg/ARZV1ReT3Mvgm/pkBgH9H2Bc/7LjJAavzbuBMxi8q38F8LExbW/czmJwNH4pg9PmM4FTN7DuMcD7Gezr7gxew8uA2XIk2as8+tqvJAkefxehJWlGGEdJajCOktRgHCWpwThKUoNxlKQG4zhFSZb0PcM4zNb9gtm7b+7XeBnHqZuIF24MZut+wezdN/drjIyjJDXMin8hs00W1LZsPyPbWsda5rNgRrY1k2brfsHM7tteL7j7sVfaQv5w+yM8eaeZO765duWfzch2HqwH2Cbbzsi2AO56+Lbbqmrn0eWz4t9Wb8v2HJTD+h5D4gvnXtT3CGNz/Ite1fcIY3He7V+4trXc02pJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUsNExzHJsiTn9D2HpLln0n/74AlA+h5C0twz0XGsqjv7nkHS3ORptSQ1THQcJakvE31avTFJlgBLALZlu56nkTTbPG6PHKtqaVUtrKqF81nQ9ziSZpnHbRwlaZyMoyQ1GEdJajCOktQw0e9WV9Wb+p5B0tzkkaMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUMNG/Q2auO2/VFX2PMDaLd92v7xHG4tg9Dul7hDFa0/cAM8ojR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGiYyjkmWJzm97zkkzV0TGUdJ6ttjxjHJEUnuTjKv+3yfJJXkc0PrfCTJ+Um2TnJmkt8nuT/J1Unem2SroXWXJTknyQlJbkyyJsmXkmy3/n7gUODvu+1Ukr229I5L0sbM24R1LgK2BRYClwCLgNu6j+stAn7AILY3Aq8FVgMHAkuBPwBnDq3/cuAm4HDg6cDXgauAk4ETgGcDvwb+qVt/9dR2S5I2z2MeOVbVPcBPgT/vFi0CTgf2TPK07ojvAGB5Va2rqg9U1eVVdU1VfR34HPD6kae9Czi+qq6sqh8C3wAO67Z3J/AgcF9V3dzdHh6dK8mSJCuSrFjH2unsuyRt0KZec1zO/x8pHgp8H7i0W/ZS4CHgMoAkx3fRWp3kHuCdwB4jz7dyJHirgKdOZfCqWlpVC6tq4XwWTOWhkvSYphLHlyV5HrAjgyPJ5QyOJhcBF1fVg0leB5wGLAMWA/sBnwW2GXm+dSOf1xRmkaSx25RrjjC47rgAeC9wUVU9nGQ58AXgFgbXGwEOAS6tqj/+GE6Svacx14PA1tN4nCRtEZt0tDZ03fEo4IJu8SXA7sDBDI4iYfCmyv5J/irJs5KcxOA0fKquAQ5MsleSpwy/2y1JM2Eq0VnO4EhzOUBVPcDguuNauuuNwOcZvPP8VeByYC/gk9OY6xMMjh5XMninevSapSSNVaqq7xk2247ZqQ7KYX2PscWdt+qKvkcYm8W77tf3CBIA59c3f1pVC0eXe7oqSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWrY1N9brR74S6gef7Z+0pP6HmFsPvfz7/Y9wlg84+nt5R45SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlLDRMUxyRFJfpJkTZLbk5yX5Hl9zyVp7pmoOALbA6cBBwKLgDuB7ybZZnTFJEuSrEiyYh1rZ3RISbPfvL4HGFZV3xr+PMkxwF0MYnnRyLpLgaUAO2anmqkZJc0NE3XkmGTvJF9N8tskdwG3MJhxj55HkzTHTNSRI3AOcANwHHAj8BCwEviT02pJGqeJiWOSJwPPBd5aVRd0y/ZngmaUNHdMUnjWALcBxya5HtgN+DiDo0dJmlETc82xqh4BXge8EPgV8BngJPCtaEkzb5KOHKmqHwPPH1m8Qx+zSJrbJubIUZImiXGUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNE/U7ZDR3nLfqir5HGIvFu+7X9whjc+weh/Q9wph8s7nUI0dJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDVOKY5LlSU4f1zCSNCk8cpSkhomPY5Jt+p5B0twznTjOS/KpJGu628eTbAWDkCU5JckNSe5LcnmSxcMPTrJvku8luTvJrUn+PckuQ/cvS3JOkvcluQG4YfN2UZKmbjpx/NvucS8BjgOWAO/o7vsScCjwBuD5wJeB7yZ5EUCSpwEXAr8CDgQOB3YAzl4f2M6hwAuBI4DDpjGjJG2WedN4zE3A26uqgF8neTbwriRnA68H9qqq67p1T09yOIOIvhV4C/Dzqnrf+idL8nfA7cBC4LJu8QPAm6tq7YaGSLKEQZjZlu2msRuStGHTOXK8pAvjehcDuwGHAAFWJrln/Q14JbB3t+6LgVeM3H99d9/eQ8/5q42FEaCqllbVwqpaOJ8F09gNSdqw6Rw5bkwBBwDrRpbf333cCvge8O7GY28Z+vO9W3guSZqS6cTxoCQZOno8GFjF4AgywC5VdcEGHvsz4LXAtVU1GlBJmhjTOa3eFTgtyXOSHAm8Bzi1qq4CzgKWJTkyyTOTLEzy7iSv7h77GeCJwNeSHNStc3iSpUmesEX2SJK2gOkcOZ4FbA1cyuA0+kzg1O6+Y4D3Ax8DdmfwRstlwAUAVbUqycuAk4EfANsC1wE/BDZ6jVGSZtKU4lhVi4Y+fVvj/nXAh7rbhp7jauDIjdz/pqnMJEnjMPH/QkaS+mAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSw5b+vdXSJlm86359jzAeW23d9wRjc+71l/c9wlhss2t7uUeOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1TEwckyxLUo3bJX3PJmnumdf3ACPOB44eWfZgH4NImtsmLY5rq+rmvoeQpIk5rZakSTJpcTwiyT0jt1NaKyZZkmRFkhXrWDvTc0qa5SbttPpCYMnIsjtaK1bVUmApwI7ZqcY7lqS5ZtLieF9V/abvISRp0k6rJWkiTNqR44Iku4wse7iqVvcyjaQ5a9LieDhw08iyG4Hde5hF0hw2MafVVfWmqkrjZhglzbiJiaMkTRLjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDWkqvqeYbMlWQ1cO0Obewpw2wxtaybN1v2C2btv7teWsWdV7Ty6cFbEcSYlWVFVC/ueY0ubrfsFs3ff3K/x8rRakhqMoyQ1GMepW9r3AGMyW/cLZu++uV9j5DVHSWrwyFGSGoyjJDUYR0lqMI6S1GAcJanh/wCuN4CaeH6K7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    n_step = 5 # number of cells(= number of Step)\n",
    "    n_hidden = 128 # number of hidden units in one cell\n",
    "\n",
    "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "    word_list = \" \".join(sentences).split()\n",
    "    word_list = list(set(word_list))\n",
    "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "    number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "    n_class = len(word_dict)  # vocab list\n",
    "\n",
    "    # hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "\n",
    "    model = Attention()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    input_batch, output_batch, target_batch = make_batch()\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(2000):\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "        loss = criterion(output, target_batch.squeeze(0))\n",
    "        if (epoch + 1) % 400 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test\n",
    "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
    "    test_batch = torch.FloatTensor(test_batch)\n",
    "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "    predict = predict.data.max(1, keepdim=True)[1]\n",
    "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "    # Show Attention\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(trained_attn, cmap='viridis')\n",
    "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
